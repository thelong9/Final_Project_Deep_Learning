{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkTcHCqjFE9Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import pandas as pd\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Replace \"YOUR_TOKEN_HERE\" with your actual token\n",
        "login(token=\"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\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aatCArYFPd-",
        "outputId": "78745a80-1917-4da9-e77a-80c87dc220d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrRQIRRKFVil",
        "outputId": "50012748-0e32-4582-90ef-3c3af15f147d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"zh-plus/tiny-imagenet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL0Zs1QqFnKc",
        "outputId": "14af7a4c-72f3-4ae5-ac9f-0ed8315d45b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUltnqKyGIDN",
        "outputId": "e46d47e3-3baa-4add-efa6-236823834803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (100000, 2), 'valid': (10000, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")"
      ],
      "metadata": {
        "id": "FvtW-WqYGNSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ep3f35nJLyF",
        "outputId": "c0f07d7d-767b-4927-a7d8-3220dada653d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train_rgb = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomApply([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    ], p=0.5),  # Áp dụng các biến đổi này với xác suất 0.5\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transform_test_rgb = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Định nghĩa các biến đổi cho ảnh grayscale\n",
        "transform_train_gray = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x),  # Chuyển đổi sang RGB nếu cần\n",
        "])\n",
        "\n",
        "transform_test_gray = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Grayscale(num_output_channels=3),  # Chuyển đổi thành RGB\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Định nghĩa Dataset cho ảnh RGB và grayscale\n",
        "class ImageNetHardDataset(Dataset):\n",
        "    def __init__(self, data, transform):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]['image'].convert('RGB')  # Chuyển đổi thành RGB\n",
        "        label = self.data[idx]['label']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "# Chia tập dữ liệu thành train và test\n",
        "train_size = int(0.8 * len(ds['train']))\n",
        "test_size = len(ds['train']) - train_size\n",
        "train_data, test_data = random_split(ds['train'], [train_size, test_size])\n",
        "\n",
        "# Tạo Dataset cho ảnh RGB và grayscale\n",
        "train_dataset_rgb = ImageNetHardDataset(train_data, transform_train_rgb)\n",
        "train_dataset_gray = ImageNetHardDataset(train_data, transform_train_gray)\n",
        "test_dataset_rgb = ImageNetHardDataset(test_data, transform_test_rgb)\n",
        "test_dataset_gray = ImageNetHardDataset(test_data, transform_test_gray)\n",
        "\n",
        "\n",
        "# Kết hợp Dataset bằng ConcatDataset\n",
        "train_dataset = ConcatDataset([train_dataset_rgb, train_dataset_gray])\n",
        "test_dataset = ConcatDataset([test_dataset_rgb, test_dataset_gray])\n",
        "\n",
        "# Tạo DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "OSfnKvdoGRA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "model = models.googlenet(weights = 'DEFAULT')"
      ],
      "metadata": {
        "id": "HA8kjVZCGlSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "   param.requires_grad = True"
      ],
      "metadata": {
        "id": "MKRBFABOQsIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 200)"
      ],
      "metadata": {
        "id": "hqGupE_8UaAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "vYOib4gzYp0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "jVhmAlaVH9Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion, device, epoch):\n",
        "    model.train()  # Chuyển mô hình sang chế độ huấn luyện\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", leave=False)  # Hiển thị tiến trình\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)  # Di chuyển dữ liệu sang thiết bị\n",
        "        optimizer.zero_grad()  # Đặt gradient về 0\n",
        "        outputs = model(inputs)  # Tính toán output\n",
        "        loss = criterion(outputs, targets)  # Tính toán loss\n",
        "        loss.backward()  # Tính toán gradient\n",
        "        optimizer.step()  # Cập nhật trọng số mô hình\n",
        "\n",
        "        total_loss += loss.item()  # Cộng dồn loss\n",
        "        _, predicted = outputs.max(1)  # Lấy dự đoán\n",
        "        total += targets.size(0)  # Cộng dồn tổng số mẫu\n",
        "        correct += predicted.eq(targets).sum().item()  # Cộng dồn số mẫu dự đoán đúng\n",
        "\n",
        "        progress_bar.set_postfix(\n",
        "            loss=f\"{total_loss / (batch_idx + 1):.3f}\",\n",
        "            acc=f\"{100. * correct / total:.2f}%\"\n",
        "        )  # Hiển thị loss và độ chính xác trên progress bar\n",
        "\n",
        "    return total_loss / len(train_loader), 100. * correct / total  # Trả về độ lỗi trung bình và độ chính xác"
      ],
      "metadata": {
        "id": "_nDkzIYGIhFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device, epoch)\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss = {train_loss:.3f}, Train Acc = {train_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUYbSe6muInh",
        "outputId": "7d216ed7-7d6e-4213-9fd7-f239e4dbf419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 4.969, Train Acc = 2.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train loss = 4.969 train acc = 2.83%"
      ],
      "metadata": {
        "id": "8hC1CcQqzKNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model AlexNet"
      ],
      "metadata": {
        "id": "Utu2XuZw-lLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = models.alexnet(weights = 'DEFAULT')"
      ],
      "metadata": {
        "id": "6K44SYWEtgq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model1.parameters():\n",
        "   param.requires_grad = True"
      ],
      "metadata": {
        "id": "e3-4pEMI1Xj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = model1.fc.in_features\n",
        "model1.fc = nn.Linear(num_features, 200)"
      ],
      "metadata": {
        "id": "Pqw_E_1pyShF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = model1.to(device)"
      ],
      "metadata": {
        "id": "wJ-27_xP11Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model1, train_loader, optimizer, criterion, device, epoch)\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss = {train_loss:.3f}, Train Acc = {train_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk3Mx3qhx22d",
        "outputId": "fb847bc1-171e-408d-b90d-3b2dfba0e694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 10.496, Train Acc = 0.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train loss = 10.496 train acc = 0.06%"
      ],
      "metadata": {
        "id": "QYAgrAhG9MCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = models.resnet50(weights = 'DEFAULT')"
      ],
      "metadata": {
        "id": "ZUqsCuEI-oiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model2.parameters():\n",
        "   param.requires_grad = True"
      ],
      "metadata": {
        "id": "ia824B6g-3N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = model2.fc.in_features\n",
        "model2.fc = nn.Linear(num_features, 200)"
      ],
      "metadata": {
        "id": "UmSMwH4e_Fc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = model2.to(device)"
      ],
      "metadata": {
        "id": "tl8w7Yo4_Ts1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model2, train_loader, optimizer, criterion, device, epoch)\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss = {train_loss:.3f}, Train Acc = {train_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJM4uHcW_Xym",
        "outputId": "6eccc2f7-df28-4747-c025-36037b097ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 5.307, Train Acc = 0.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train loss = 5.307, train acc = 0.47%"
      ],
      "metadata": {
        "id": "iVCWUfvgM6v-"
      }
    }
  ]
}