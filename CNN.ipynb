{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k0Mrm2cnXL0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import random_split, ConcatDataset\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tarfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P80j0WS_nmVb",
        "outputId": "cbc724b5-6ae3-41a8-c18a-1fcb93df9d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"zh-plus/tiny-imagenet\")"
      ],
      "metadata": {
        "id": "qajitZbcnoNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFZgCqqtnrcN",
        "outputId": "8eef954a-3965-448e-cb05-b1f532f885ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['image', 'label'],\n",
            "        num_rows: 100000\n",
            "    })\n",
            "    valid: Dataset({\n",
            "        features: ['image', 'label'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "X5D7AkK1SY5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyImageNetDataset(Dataset):\n",
        "    def __init__(self, dataset_split, transform=None):\n",
        "        self.data = dataset_split\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]['image'].convert('RGB')\n",
        "        label = self.data[idx]['label']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "AuJcR7B_nuOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TinyImageNetDataset(dataset['train'], train_transforms)\n",
        "val_data = TinyImageNetDataset(dataset['valid'], val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "iNwS_-iaanit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=200):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 8 * 8, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Poz3nUqFnw9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN(num_classes=200).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "c4zQz6RQnybF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100. * correct / total\n",
        "    return running_loss / len(loader), train_accuracy"
      ],
      "metadata": {
        "id": "hDSL5Lqinzg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    accuracy = 100. * correct / total\n",
        "    return val_loss / len(loader), accuracy"
      ],
      "metadata": {
        "id": "k_2G0xDqn0sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_accuracy = evaluate(model, val_loader, criterion, device)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI-XRzOyn1z3",
        "outputId": "9d4aa511-ea10-4adb-a489-17c713f9a3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Train Loss: 4.7637, Val Loss: 4.1076, Val Accuracy: 12.58%\n",
            "Epoch 2/30, Train Loss: 4.0382, Val Loss: 3.7564, Val Accuracy: 17.86%\n",
            "Epoch 3/30, Train Loss: 3.7625, Val Loss: 3.5173, Val Accuracy: 21.23%\n",
            "Epoch 4/30, Train Loss: 3.6183, Val Loss: 3.4079, Val Accuracy: 23.59%\n",
            "Epoch 5/30, Train Loss: 3.5197, Val Loss: 3.3158, Val Accuracy: 24.71%\n",
            "Epoch 6/30, Train Loss: 3.4474, Val Loss: 3.2919, Val Accuracy: 25.92%\n",
            "Epoch 7/30, Train Loss: 3.3988, Val Loss: 3.2401, Val Accuracy: 25.96%\n",
            "Epoch 8/30, Train Loss: 3.3438, Val Loss: 3.2691, Val Accuracy: 26.00%\n",
            "Epoch 9/30, Train Loss: 3.3042, Val Loss: 3.2369, Val Accuracy: 26.35%\n",
            "Epoch 10/30, Train Loss: 3.2660, Val Loss: 3.1801, Val Accuracy: 27.94%\n",
            "Epoch 11/30, Train Loss: 3.2361, Val Loss: 3.1913, Val Accuracy: 27.45%\n",
            "Epoch 12/30, Train Loss: 3.2125, Val Loss: 3.1527, Val Accuracy: 28.21%\n",
            "Epoch 13/30, Train Loss: 3.1847, Val Loss: 3.1340, Val Accuracy: 28.46%\n",
            "Epoch 14/30, Train Loss: 3.1665, Val Loss: 3.1140, Val Accuracy: 29.21%\n",
            "Epoch 15/30, Train Loss: 3.1414, Val Loss: 3.0846, Val Accuracy: 29.57%\n",
            "Epoch 16/30, Train Loss: 3.1248, Val Loss: 3.0812, Val Accuracy: 30.15%\n",
            "Epoch 17/30, Train Loss: 3.1099, Val Loss: 3.1164, Val Accuracy: 28.63%\n",
            "Epoch 18/30, Train Loss: 3.0914, Val Loss: 3.0702, Val Accuracy: 30.21%\n",
            "Epoch 19/30, Train Loss: 3.0749, Val Loss: 3.0396, Val Accuracy: 30.51%\n",
            "Epoch 20/30, Train Loss: 3.0553, Val Loss: 3.0456, Val Accuracy: 29.85%\n",
            "Epoch 21/30, Train Loss: 3.0410, Val Loss: 3.0229, Val Accuracy: 30.74%\n",
            "Epoch 22/30, Train Loss: 3.0274, Val Loss: 3.0257, Val Accuracy: 31.13%\n",
            "Epoch 23/30, Train Loss: 3.0161, Val Loss: 3.0232, Val Accuracy: 31.09%\n",
            "Epoch 24/30, Train Loss: 3.0048, Val Loss: 3.0380, Val Accuracy: 30.13%\n",
            "Epoch 25/30, Train Loss: 2.9857, Val Loss: 3.0077, Val Accuracy: 30.63%\n",
            "Epoch 26/30, Train Loss: 2.9879, Val Loss: 2.9940, Val Accuracy: 31.35%\n",
            "Epoch 27/30, Train Loss: 2.9684, Val Loss: 2.9711, Val Accuracy: 31.77%\n",
            "Epoch 28/30, Train Loss: 2.9550, Val Loss: 3.0141, Val Accuracy: 31.09%\n",
            "Epoch 29/30, Train Loss: 2.9531, Val Loss: 3.0017, Val Accuracy: 31.31%\n",
            "Epoch 30/30, Train Loss: 2.9386, Val Loss: 3.0370, Val Accuracy: 30.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hiddenlayer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KfNyMCGV0Uv",
        "outputId": "e34af357-3d31-4c11-fa13-cc30919e9d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hiddenlayer\n",
            "  Downloading hiddenlayer-0.3-py3-none-any.whl.metadata (703 bytes)\n",
            "Downloading hiddenlayer-0.3-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: hiddenlayer\n",
            "Successfully installed hiddenlayer-0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUYSsjwQZp6S",
        "outputId": "a86d47a6-3c95-493b-d290-ac102526e787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_accuracy = evaluate(model, val_loader, criterion, device)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "L05g4sCsdl31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763ff17d-9d99-49a8-b81d-306bb5014557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Train Loss: 4.5879, Train Accuracy: 7.23%, Val Loss: 3.9378, Val Accuracy: 15.10%\n",
            "Epoch 2/20, Train Loss: 3.8666, Train Accuracy: 16.14%, Val Loss: 3.5229, Val Accuracy: 21.01%\n",
            "Epoch 3/20, Train Loss: 3.5798, Train Accuracy: 20.58%, Val Loss: 3.3637, Val Accuracy: 24.24%\n",
            "Epoch 4/20, Train Loss: 3.3801, Train Accuracy: 23.66%, Val Loss: 3.2962, Val Accuracy: 25.58%\n",
            "Epoch 5/20, Train Loss: 3.2362, Train Accuracy: 26.03%, Val Loss: 3.2379, Val Accuracy: 26.67%\n",
            "Epoch 6/20, Train Loss: 3.1085, Train Accuracy: 27.98%, Val Loss: 3.2096, Val Accuracy: 26.37%\n",
            "Epoch 7/20, Train Loss: 2.9913, Train Accuracy: 30.04%, Val Loss: 3.2006, Val Accuracy: 26.92%\n",
            "Epoch 8/20, Train Loss: 2.8755, Train Accuracy: 31.80%, Val Loss: 3.1858, Val Accuracy: 27.36%\n",
            "Epoch 9/20, Train Loss: 2.7635, Train Accuracy: 33.84%, Val Loss: 3.1867, Val Accuracy: 27.36%\n",
            "Epoch 10/20, Train Loss: 2.6658, Train Accuracy: 35.46%, Val Loss: 3.2463, Val Accuracy: 26.96%\n",
            "Epoch 11/20, Train Loss: 2.5684, Train Accuracy: 37.20%, Val Loss: 3.2420, Val Accuracy: 26.84%\n",
            "Epoch 12/20, Train Loss: 2.4787, Train Accuracy: 38.85%, Val Loss: 3.2728, Val Accuracy: 26.59%\n",
            "Epoch 13/20, Train Loss: 2.3882, Train Accuracy: 40.38%, Val Loss: 3.3590, Val Accuracy: 26.18%\n",
            "Epoch 14/20, Train Loss: 2.3069, Train Accuracy: 41.77%, Val Loss: 3.3555, Val Accuracy: 26.51%\n",
            "Epoch 15/20, Train Loss: 2.2176, Train Accuracy: 43.26%, Val Loss: 3.4034, Val Accuracy: 26.08%\n",
            "Epoch 16/20, Train Loss: 2.1273, Train Accuracy: 45.09%, Val Loss: 3.4856, Val Accuracy: 25.94%\n",
            "Epoch 17/20, Train Loss: 2.0567, Train Accuracy: 46.76%, Val Loss: 3.5251, Val Accuracy: 25.29%\n",
            "Epoch 18/20, Train Loss: 1.9728, Train Accuracy: 48.43%, Val Loss: 3.5870, Val Accuracy: 25.14%\n",
            "Epoch 19/20, Train Loss: 1.8894, Train Accuracy: 50.08%, Val Loss: 3.6117, Val Accuracy: 24.75%\n",
            "Epoch 20/20, Train Loss: 1.8136, Train Accuracy: 51.60%, Val Loss: 3.6596, Val Accuracy: 24.28%\n"
          ]
        }
      ]
    }
  ]
}